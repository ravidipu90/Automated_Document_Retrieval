{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai==0.28\n",
        "!pip install langchain\n",
        "!pip install faiss-cpu\n",
        "!pip install tiktoken\n",
        "!pip install langchain_community\n",
        "!pip install pypdf\n",
        "!pip install transformers\n",
        "!pip install sentence_transformers\n",
        "!pip install slack_sdk\n",
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcOn9EW44TL8",
        "outputId": "44be3a78-2a02-455b-e547-0f9c44c86067"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.10/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (4.66.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai==0.28) (3.10.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai==0.28) (2024.7.4)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai==0.28) (4.0.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.14)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.10.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.32 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.33)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.32->langchain) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.32->langchain) (3.0.0)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.8.0.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.13 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.14)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.30 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.99)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.3.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.13->langchain_community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.30->langchain_community) (4.12.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.30->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.13->langchain_community) (2.20.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.12.2)\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3070, in _dep_map\n",
            "    return self.__dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2863, in __getattr__\n",
            "    raise AttributeError(attr)\n",
            "AttributeError: _DistInfoDistribution__dep_map\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 179, in exc_logging_wrapper\n",
            "    status = run_func(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/req_command.py\", line 67, in wrapper\n",
            "    return func(self, options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 447, in run\n",
            "    conflicts = self._determine_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/commands/install.py\", line 578, in _determine_conflicts\n",
            "    return check_install_conflicts(to_install)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 101, in check_install_conflicts\n",
            "    package_set, _ = create_package_set_from_installed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/operations/check.py\", line 42, in create_package_set_from_installed\n",
            "    dependencies = list(dist.iter_dependencies())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/metadata/pkg_resources.py\", line 247, in iter_dependencies\n",
            "    return self._dist.requires(extras)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 2786, in requires\n",
            "    dm = self._dep_map\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3072, in _dep_map\n",
            "    self.__dep_map = self._compute_dependencies()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3082, in _compute_dependencies\n",
            "    reqs.extend(parse_requirements(req))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/pkg_resources/__init__.py\", line 3135, in __init__\n",
            "    super().__init__(requirement_string)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/requirements.py\", line 43, in __init__\n",
            "    self.specifier: SpecifierSet = SpecifierSet(parsed.specifier)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/specifiers.py\", line 718, in __init__\n",
            "    self._specs = frozenset(map(Specifier, split_specifiers))\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_vendor/packaging/specifiers.py\", line 331, in __hash__\n",
            "    return hash(self._canonical_spec)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1732, in isEnabledFor\n",
            "    return self._cache[level]\n",
            "KeyError: 50\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/main.py\", line 80, in main\n",
            "    return command.main(cmd_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 100, in main\n",
            "    return self._main(args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 232, in _main\n",
            "    return run(options, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pip/_internal/cli/base_command.py\", line 215, in exc_logging_wrapper\n",
            "    logger.critical(\"Operation cancelled by user\")\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1523, in critical\n",
            "    if self.isEnabledFor(CRITICAL):\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1740, in isEnabledFor\n",
            "    level >= self.getEffectiveLevel()\n",
            "  File \"/usr/lib/python3.10/logging/__init__.py\", line 1718, in getEffectiveLevel\n",
            "    while logger:\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.5)\n",
            "Requirement already satisfied: numpy<2.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "from operator import itemgetter\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
        "from langchain.schema import format_document\n",
        "from langchain.prompts.prompt import PromptTemplate\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "\n",
        "\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "\n",
        "\n",
        "load_dotenv()\n",
        "gpt_model_name = 'gpt-4o-mini'\n",
        "\n",
        "\n",
        "\n",
        "def retriever(file_path, k=2):\n",
        "    assert file_path.endswith('.pdf'), \"PDF files are the only supported format\"\n",
        "    loader = PyPDFLoader(file_path)\n",
        "    pages = loader.load_and_split()\n",
        "\n",
        "    model_name = 'sentence-transformers/all-MiniLM-L6-v2'\n",
        "    model_kwargs = {'device': 'cpu'}\n",
        "    encode_kwargs = {'normalize_embeddings': True}\n",
        "    embedding_model = HuggingFaceEmbeddings(\n",
        "        model_name=model_name,\n",
        "        model_kwargs=model_kwargs,\n",
        "        encode_kwargs=encode_kwargs\n",
        "    )\n",
        "    faiss_index = FAISS.from_documents(pages, embedding_model)\n",
        "    retriever = faiss_index.as_retriever(search_kwargs={\"k\": k})\n",
        "\n",
        "    return retriever\n",
        "\n",
        "\n",
        "standalone_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
        "                      Chat History:\n",
        "                      {chat_history}\n",
        "                      Follow Up Input: {question}\n",
        "                      Standalone question:\n",
        "                      \"\"\"\n",
        "STANDALONE_QUESTION_PROMPT = PromptTemplate.from_template(standalone_template)\n",
        "\n",
        "answer_template = \"\"\"Answer the question based only on the following context:\n",
        "                    {context}\n",
        "\n",
        "                    Question: {question}\n",
        "                  \"\"\"\n",
        "ANSWER_PROMPT = ChatPromptTemplate.from_template(answer_template)\n",
        "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
        "\n",
        "\n",
        "\n",
        "def _combine_documents(\n",
        "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
        "):\n",
        "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
        "    combined_docs=document_separator.join(doc_strings)\n",
        "    return combined_docs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def llm_chain(retriever,memory):\n",
        "    loaded_memory = RunnablePassthrough.assign(\n",
        "        chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
        "    )\n",
        "    # Now we calculate the standalone question\n",
        "    standalone_question = {\n",
        "        \"standalone_question\": {\n",
        "            \"question\": lambda x: x[\"question\"],\n",
        "            \"chat_history\": lambda x: x[\"chat_history\"],\n",
        "        }\n",
        "        | STANDALONE_QUESTION_PROMPT\n",
        "        | ChatOpenAI(temperature=0,model=gpt_model_name)\n",
        "        | StrOutputParser(),\n",
        "    }\n",
        "    # Now we retrieve the documents\n",
        "    retrieved_documents = {\n",
        "        \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
        "        \"question\": lambda x: x[\"standalone_question\"],\n",
        "    }\n",
        "    # Now we construct the inputs for the final prompt\n",
        "    final_inputs = {\n",
        "        \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
        "        \"question\": itemgetter(\"question\"),\n",
        "    }\n",
        "    # And finally, we do the part that returns the answers\n",
        "    answer = {\n",
        "        \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(temperature=0,model=gpt_model_name),\n",
        "        \"docs\": itemgetter(\"docs\"),\n",
        "    }\n",
        "    # And now we put it all together!\n",
        "    final_chain = loaded_memory | standalone_question | retrieved_documents | answer\n",
        "    return final_chain"
      ],
      "metadata": {
        "id": "DBgzwrKmPemh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/handbook.pdf'\n",
        "retriever_=retriever(file_path,k=2)\n",
        "memory = ConversationBufferMemory()\n",
        "chain=llm_chain(retriever_,memory)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZ2AzgFEPvwZ",
        "outputId": "d7639e08-b600-4ea9-c775-11859cfea285"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
            "  from tqdm.autonotebook import tqdm, trange\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:141: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from slack_sdk import WebClient\n",
        "from slack_sdk.errors import SlackApiError\n",
        "import os\n",
        "\n",
        "\n",
        "client = WebClient(token=os.getenv(\"SLACK_USER_TOKEN\"))\n",
        "def send_message_to_slack(channel_name, message):\n",
        "    \"\"\"\n",
        "    Name:\n",
        "      send_message_to_slack.\n",
        "    Description:\n",
        "      Used to send a message to a slack channel named 'channel_name'.\n",
        "    Args:\n",
        "      channel_name : Chanel name to send the message to\n",
        "      message: The message to send\n",
        "    Required:\n",
        "      channel_name\n",
        "      message\n",
        "\n",
        "    Returns:\n",
        "      A JSON string containing the channel_name and  message.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        response = client.chat_postMessage(channel=channel_name, text=message)\n",
        "        print(\"\\tPosted Successfully!\")\n",
        "    except SlackApiError as e:\n",
        "        print(f\"Error posting message: {e.response['error']}\")\n",
        "\n",
        "\n",
        "def search_information_in_document(query):\n",
        "    \"\"\"\n",
        "    Name:\n",
        "      search_information_in_document.\n",
        "    Description:\n",
        "      Search any information in the document.\n",
        "    Args:\n",
        "      query : query to search\n",
        "    Required:\n",
        "      query\n",
        "\n",
        "    Returns:\n",
        "      A JSON string containing the query.\n",
        "\n",
        "    \"\"\"\n",
        "    inputs = {\"question\": question}\n",
        "    result = chain.invoke(inputs)\n",
        "    memory.save_context(inputs, {\"answer\": result[\"answer\"].content})\n",
        "\n",
        "    return result[\"answer\"].content\n",
        "\n",
        "\n",
        "print(search_information_in_document.__doc__)\n",
        "print(send_message_to_slack.__doc__)\n"
      ],
      "metadata": {
        "id": "Q0XvtdwEQ60m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4f565e0-4424-4444-916a-ec6ade1d6a6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    Name:\n",
            "      search_information_in_document.\n",
            "    Description:\n",
            "      Search any information in the document.\n",
            "    Args:\n",
            "      query : query to search\n",
            "    Required:\n",
            "      query\n",
            "\n",
            "    Returns:\n",
            "      A JSON string containing the query.\n",
            "\n",
            "    \n",
            "\n",
            "    Name:\n",
            "      send_message_to_slack.\n",
            "    Description:\n",
            "      Used to send a message to a slack channel named 'channel_name'.\n",
            "    Args:\n",
            "      channel_name : Chanel name to send the message to\n",
            "      message: The message to send\n",
            "    Required:\n",
            "      channel_name\n",
            "      message\n",
            "\n",
            "    Returns:\n",
            "      A JSON string containing the channel_name and  message.\n",
            "\n",
            "    \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"\"\"\n",
        "You are designed to help with a variety of tasks, To answer any query use the provide tools only.\n",
        "\n",
        "## Tools\n",
        "You have access to a wide variety of tools. You are responsible for using\n",
        "the tools in any sequence you deem appropriate to complete the task at hand.\n",
        "\n",
        "You have access to the following tools:\n",
        "{tool_desc}\n",
        "\n",
        "## Answer format\n",
        "Answer the question by considering chat_history and observation. Answer should be in the following format.\n",
        "\n",
        "1. Use this format if you need a tool to get some information before giving a final answer.\n",
        "  Thought: I need to use a tool to help me answer the question.\n",
        "  Action: Tool name without any quotes, if using a tool.\n",
        "  Action Input: The input to the tool, in a JSON format representing the kwargs.\n",
        "\n",
        "2. Use this format if either the final answer is there in the observation or you don't need any tool to get the final answer.\n",
        "  Thought: I can answer without using any more tools.\n",
        "  Answer: [Your answer here]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "user_prompt=\"\"\"\n",
        "### Chat History:\n",
        "{chat_history}\n",
        "\n",
        "### Observation:\n",
        "{observation}\n",
        "\n",
        "### Question :\n",
        "{question}\n",
        "\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "C04HzZys84RQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import re\n",
        "def extract_tool_use(input_text):\n",
        "    pattern = r\"\\s*Thought:(.*?)Action:(.*?)Action Input:(.*?)(?:\\n|$)\"\n",
        "\n",
        "    match = re.search(pattern, input_text, re.DOTALL)\n",
        "    if not match:\n",
        "        raise ValueError(f\"Could not extract tool use from input text: {input_text}\")\n",
        "\n",
        "    thought = match.group(1).strip()\n",
        "    action = match.group(2).strip()\n",
        "    action_input = match.group(3).strip()\n",
        "    action_input=json.loads(action_input)\n",
        "    return thought, action, action_input\n",
        "\n"
      ],
      "metadata": {
        "id": "1klbj9ypYYhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "questions=[\"What is the name of the company, send this information to 'coding' slack channel\",\n",
        "           'Who is the CEO of the company?']\n",
        "\n",
        "observation=''\n",
        "chat_histroy=[]\n",
        "tools={fun.__name__:fun for fun in [search_information_in_document, send_message_to_slack]}\n",
        "\n",
        "system_message= system_prompt.format(tool_desc=[tools[tool].__doc__ for tool in tools])\n",
        "\n",
        "for question in questions:\n",
        "  print(f\"\\nQuestion: {question}\")\n",
        "\n",
        "  for _ in range(3):\n",
        "    user_message=user_prompt.format(question=question,\n",
        "                                    chat_history='\\n'.join(chat_histroy),\n",
        "                                    observation=observation)\n",
        "\n",
        "    #print(f\"User Message: \\n {'*'*50} \\n {user_message}\")\n",
        "    messages = [\n",
        "      {\"role\": \"system\", \"content\":system_message},\n",
        "      {\"role\": \"user\", \"content\": user_message}\n",
        "      ]\n",
        "    response = openai.ChatCompletion.create(\n",
        "          model=gpt_model_name,\n",
        "          messages=messages,\n",
        "      )\n",
        "    response=response[\"choices\"][0][\"message\"]\n",
        "\n",
        "    if \"Action:\" in response['content']:\n",
        "      thought, action, action_input=extract_tool_use(response['content'])\n",
        "      tool=tools[action]\n",
        "      print(f\"\\tThought: {thought}\")\n",
        "      print(f\"\\tAction: {action}\")\n",
        "      print(f\"\\tAction Input: {action_input}\")\n",
        "      observation=tool(**action_input)\n",
        "\n",
        "    else:\n",
        "      thought, answer=response['content'].split('\\n')\n",
        "      thought=thought.split(':')[-1].strip()\n",
        "      answer=answer.split(':')[-1].strip()\n",
        "      print(f\"\\tThought: {thought}\")\n",
        "      print(f\"\\tAnswer: {answer}\")\n",
        "      break\n",
        "    print('\\n')\n",
        "\n",
        "    chat_histroy.append(f\"User: \\n {question}\")\n",
        "    chat_histroy.append(f\"Assistant: \\n {response['content']}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P61ccIrRONx6",
        "outputId": "b24db309-496e-4ccf-f2c4-83c64b3aa150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Question: What is the name of the company, send this information to 'coding' slack channel\n",
            "\tThought: I need to use a tool to help me answer the question.\n",
            "\tAction: search_information_in_document\n",
            "\tAction Input: {'query': 'name of the company'}\n",
            "\n",
            "\n",
            "\tThought: I can answer without using any more tools.\n",
            "\tAction: send_message_to_slack\n",
            "\tAction Input: {'channel_name': 'coding', 'message': 'The name of the company is Zania, Inc.'}\n",
            "\tPosted Successfully!\n",
            "\n",
            "\n",
            "\tThought: I need to use a tool to help me answer the question.\n",
            "\tAction: search_information_in_document\n",
            "\tAction Input: {'query': 'name of the company'}\n",
            "\n",
            "\n",
            "\n",
            "Question: Who is the CEO of the company?\n",
            "\tThought: I need to use a tool to help me answer the question.\n",
            "\tAction: search_information_in_document\n",
            "\tAction Input: {'query': 'CEO of the company'}\n",
            "\n",
            "\n",
            "\tThought: I can answer without using any more tools.\n",
            "\tAnswer: The CEO of Zania, Inc. is Shruti Gupta.\n"
          ]
        }
      ]
    }
  ]
}